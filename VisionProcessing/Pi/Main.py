#!/usr/bin/python
# -*- coding: utf-8 -*-
import threading
import cv2
import socket
import time
import numpy as np
import signal
import atexit
from networktables import NetworkTables
from enum import Enum

# Only keep the threads running barring a halt
isOn = False
lock = threading.Lock()
class Main:

    """
    Executive class for controlling flow
    """

    SOCK_IP = '10.2.63.5'  # Static IP for Driver's Station on FMS
    SOCK_PORT = 5810  # TCIP Port to use for communication with Driver's Station
    NT_IP = 'roboRIO-263-FRC.local'  # RIO server IP for NetworkTables

    def __init__(self):

	#register exit methods
	atexit.register(Sender.sender_exit)
	atexit.register(ImageRetriever.image_exit)

        """initializes all threads and class instances
        """
        self.image_retrieval = ImageRetriever()
        self.image_processor = FindTape()
        self.image_sender = Sender(self.SOCK_IP, self.SOCK_PORT, self.NT_IP)
        #Create continual threads to run
        self.processor_t = threading.Thread(name='image_processor',
                target=self.image_processor.update,
                args=(self.image_retrieval,self.image_sender))
        self.sender_t = threading.Thread(name='image_sender',
                target=self.image_sender.update_camera_feed,
                args=(self.image_retrieval, ))
       # self.toggle_t = threading.Thread(name = 'image_toggle',
          #      target = self.image_sender.toggleThread,)


    def start(self):
        """responsible for starting threads that will continue until bot is in off state
        """
        self.processor_t.start()
        self.sender_t.start()
        #self.toggle_t.start()


class FindTape:

    """
    An OpenCV pipeline generated by GRIP and modified by FIRST Team 263.
    """
    BlurType = Enum('BlurType','Box_Blur Gaussian_Blur Median_Filter Bilateral_Filter')
    filtered = False
    def __init__(self):
        """initializes all values to presets or None if need to be set
        """

        self.__hsl_threshold_hue = [58.70503597122302,
                                    90.88395904436861]
        self.__hsl_threshold_saturation = [25.0, 150.70819112627989]
        self.__hsl_threshold_luminance = [101.21223021582733, 255.0]

        self.hsl_threshold_output = None

        self.__blur_input = self.hsl_threshold_output
        self.__blur_type = self.BlurType.Box_Blur
        self.__blur_radius = 1.8018018018018018

        self.blur_output = None
        self.__find_contours_input = self.blur_output
        self.__find_contours_external_only = False

        self.find_contours_output = None
        self.__filter_contours_contours = self.find_contours_output
        self.__filter_contours_min_area =1.0
        self.__filter_contours_min_perimeter = 0.0
        self.__filter_contours_min_width = 2.5
        self.__filter_contours_max_width = 1000.0
        self.__filter_contours_min_height = 2.5
        self.__filter_contours_max_height = 1000.0
        self.__filter_contours_solidity = [26.32446043165468, 100]
        self.__filter_contours_max_vertices = 1000000.0
        self.__filter_contours_min_vertices = 0.0
        self.__filter_contours_min_ratio = 0.0
        self.__filter_contours_max_ratio = 1000.0

        self.filter_contours_output = None

    def update(self, retriever, nt_manager):
        """Continually updates both camera feeds' data through NetworkTables
        """
        global isOn
        while isOn:
	    try:
		#print('trying everything')
	        pGear = self.process(retriever.get_latest_gear())
	        pShooter = self.process(retriever.get_latest_shooter())
		#print('tried everything')
            except:
                continue
	    
            if True:
                nt_manager.update_gear_coords(pGear)
		#print('i might see gear')
	
	    if(len(pShooter) == 2):
                nt_manager.update_shooter_coords(pShooter[0],pShooter[1])
		#print('i see shooter')
    def rohan(frame):
	c = 0
	contourL = []
	hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)

	upper = np.array([45,0,225])
	lower = np.array([46,30,255])
	#upper = np.array([0,0,254])
	#lower = np.array([0,0,255])
	#h = cv2.getTrackbarPos('Min Hue','Final')
	#s = cv2.getTrackbarPos('Min Saturation','Final')
	#v = cv2.getTrackbarPos('Min Value','Final')
	#mh = cv2.getTrackbarPos('Max Hue','Final')
	#ms = cv2.getTrackbarPos('Max Saturation','Final')
	#mv = cv2.getTrackbarPos('Max Value','Final')
	#upper = np.array([h,s,v])
	#lower = np.array([mh,ms,mv])

	mask = cv2.inRange(hsv,upper,lower)
	mask = cv2.bitwise_and(frame, frame, mask = mask)
	erode = cv2.erode(mask,(15,15),iterations = 4)
	dilate = cv2.dilate(erode,(15,15 ), iterations = 1)
	self.tape = cv2.erode(dilate,(15,15),iterations = 4)

	gray = cv2.cvtColor(self.tape,cv2.COLOR_BGR2GRAY)
	_,thresh = cv2.threshold(gray,127,255,0)

	x, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
	for contour in contours:
		epsilon = 0.02*cv2.arcLength(contour,True)
		approx = cv2.approxPolyDP(contour,epsilon,True)
		#print len(approx)
		if len(approx) > 0 and cv2.contourArea(contour) >  cv2.getTrackbarPos('Min Area','Final'):
			cv2.drawContours(self.tape,[contour],-1,(127,58,254), 3)
			M = cv2.moments(contour)
			cx = int(M['m10']/M['m00'])
			cy = int(M['m01']/M['m00'])
			centroid = (cx,cy)
			contourL.append(centroid)
			c += 1
			cv2.circle(self.tape,centroid,5,(0,255,0),thickness = -1)
			cv2.putText(self.tape,'Center',(cx+5,cy+5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,0,0),1,cv2.LINE_AA)
		else:
			cv2.drawContours(self.tape,[contour],-1,0,-1)
		if c % 2 == 0:
			return contours	
		self.filtered = True
    def process(self, source0):
        """
	Runs the pipeline and sets all outputs to new values.
	"""
	#print('processing...')
        # Step HSL_Threshold0:

        self.__hsl_threshold_input = source0
        self.hsl_threshold_output = \
            self.__hsl_threshold(self.__hsl_threshold_input,
                                 self.__hsl_threshold_hue,
                                 self.__hsl_threshold_saturation,
                                 self.__hsl_threshold_luminance)

        # Step Blur0:

        self.__blur_input = self.hsl_threshold_output
        self.blur_output = self.__blur(self.__blur_input,
                self.__blur_type, self.__blur_radius)

        # Step Find_Contours0:

        self.__find_contours_input = self.blur_output
        self.find_contours_output = \
            self.__find_contours(self.__find_contours_input,
                                 self.__find_contours_external_only)

        # Step Filter_Contours0:

        self.__filter_contours_contours = self.find_contours_output
	#print('processed')
        return self.__filter_contours(
            self.__filter_contours_contours,
            self.__filter_contours_min_area,
            self.__filter_contours_min_perimeter,
            self.__filter_contours_min_width,
            self.__filter_contours_max_width,
            self.__filter_contours_min_height,
            self.__filter_contours_max_height,
            self.__filter_contours_solidity,
            self.__filter_contours_max_vertices,
            self.__filter_contours_min_vertices,
            self.__filter_contours_min_ratio,
            self.__filter_contours_max_ratio,
            )

    @staticmethod
    def __hsl_threshold(
        input,
        hue,
        sat,
        lum,
        ):
        """Segment an image based on hue, saturation, and luminance ranges.
........Args:
............input: A BGR numpy.ndarray.
............hue: A list of two numbers the are the min and max hue.
............sat: A list of two numbers the are the min and max saturation.
............lum: A list of two numbers the are the min and max luminance.
........Returns:
............A black and white numpy.ndarray.
........"""

        out = cv2.cvtColor(input, cv2.COLOR_BGR2HLS)
        return cv2.inRange(out, (hue[0], lum[0], sat[0]), (hue[1],
                           lum[1], sat[1]))

    @classmethod
    def __blur(self, src, type, radius):
        """Softens an image using one of several filters.
........Args:
........src: The source mat (numpy.ndarray).
........type: The blurType to perform represented as an int.
........radius: The radius for the blur as a float.
........Returns:
........A numpy.ndarray that has been blurred.
........"""

        if type is self.BlurType.Box_Blur:
            ksize = int(2 * round(radius) + 1)
            return cv2.blur(src, (ksize, ksize))
        elif type is self.BlurType.Gaussian_Blur:
            ksize = int(6 * round(radius) + 1)
            return cv2.GaussianBlur(src, (ksize, ksize), round(radius))
        elif type is self.BlurType.Median_Filter:
            ksize = int(2 * round(radius) + 1)
            return cv2.medianBlur(src, ksize)
        else:
            return cv2.bilateralFilter(src, -1, round(radius),
                    round(radius))

    @staticmethod
    def __find_contours(input, external_only):
        """Sets the values of pixels in a binary image to their distance to the nearest black pixel.
........Args:
............input: A numpy.ndarray.
............external_only: A boolean. If true only external contours are found.
........Return:
............A list of numpy.ndarray where each one represents a contour.
........"""

        if external_only:
            mode = cv2.RETR_EXTERNAL
        else:
            mode = cv2.RETR_LIST
        method = cv2.CHAIN_APPROX_SIMPLE
        (im2, contours, hierarchy) = cv2.findContours(input, mode=mode,
                method=method)
        return contours

    @staticmethod
    def __filter_contours(
        input_contours,
        min_area,
        min_perimeter,
        min_width,
        max_width,
        min_height,
        max_height,
        solidity,
        max_vertex_count,
        min_vertex_count,
        min_ratio,
        max_ratio,
        ):
        """Filters out contours that do not meet certain criteria.
........Args:
............input_contours: Contours as a list of numpy.ndarray.
............min_area: The minimum area of a contour that will be kept.
............min_perimeter: The minimum perimeter of a contour that will be kept.
............min_width: Minimum width of a contour.
............max_width: MaxWidth maximum width.
............min_height: Minimum height.
............max_height: Maximum height.
............solidity: The minimum and maximum solidity of a contour.
............min_vertex_count: Minimum vertex Count of the contours.
............max_vertex_count: Maximum vertex Count.
............min_ratio: Minimum ratio of width to height.
............max_ratio: Maximum ratio of width to height.
........Returns:
............Contours as a list of numpy.ndarray.
........"""

        output = []
        for contour in input_contours:
            (x, y, w, h) = cv2.boundingRect(contour)
            if w < min_width or w > max_width:
                continue
            if h < min_height or h > max_height:
                continue
            area = cv2.contourArea(contour)
            if area < min_area:
                continue
            if cv2.arcLength(contour, True) < min_perimeter:
                continue
            hull = cv2.convexHull(contour)
            solid = 100 * area / cv2.contourArea(hull)
            if solid < solidity[0] or solid > solidity[1]:
                continue
            if len(contour) < min_vertex_count or len(contour) \
                > max_vertex_count:
                continue
            ratio = float(w) / h
            if ratio < min_ratio or ratio > max_ratio:
                continue
            output.append(contour)
        return output

    def getCoords(self):
        return self.name


class Sender:
    """
    Class responsible for all data sent from Raspberry Pi to both NT server and DS server
    """

    NetworkTables.initialize(server='roboRIO-263-FRC.local')
    gear = NetworkTables.getTable('cameraData/gear')
    shooter = NetworkTables.getTable('cameraData/shooter')
    camera_data = NetworkTables.getTable('cameraData/clientMode')
    #print('tables are initialized')
    FRAMERATE_PERIOD = 1 / 15 #its 0 unless 15 is 15.0
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    #toggle = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    def __init__(self,serverIP, serverPort, networktableIP):

        self.mode_gear = True

        while True:
            try:
                #print('Trying to connect to ' + serverIP + ' on port ' + str(serverPort))
                self.sock.connect((serverIP, serverPort))
                #self.toggle.connect(('roboRIO-263-FRC.local',5800))
                break
            except Exception as e:
		pass
                #print('Failed to connect: ' + str(e))
        print('Connected')

    def update_camera_feed(self, retriever):
        global isOn
        while isOn:   
            self.mode_gear = self.camera_data.getBoolean('gearMode', defaultValue=True)
            if self.mode_gear:
                frame = retriever.get_latest_gear()
	    else:	
                frame = retriever.get_latest_shooter()
            if frame is None: return
            im = cv2.imencode('.jpg', frame)[1].tostring()
            self.sock.send(im)
            time.sleep(self.FRAMERATE_PERIOD)
	    
    @classmethod
    def update_gear_coords(self, contours):
	#print('updating gear coords')
	if (len(contours) is not 2):
	   #print('sending -1s')
	   self.gear.putNumber('pointOneX', -1)
	   self.gear.putNumber('pointOneY', -1)
	   self.gear.putNumber('pointTwoX', -1)
	   self.gear.putNumber('pointTwoY', -1)
	else: 
	    #print('sending other values')
	    (p1x,p1y,p1w,p1h) = cv2.boundingRect(contours[0])
	    p1x += p1w/2.0
	    p1y += p1h/2.0
	    (p2x,p2y,p2w,p2h) = cv2.boundingRect(contours[1])
	    p2x += p2w/2.0
	    p2y += p2h/2.0	

            self.gear.putNumber('pointOneX', p1x)
            self.gear.putNumber('pointOneY', p1y)
            self.gear.putNumber('pointTwoX', p2x)
            self.gear.putNumber('pointTwoY', p2y)
	#print('updated gear coords')
    @classmethod
    def update_shooter_coords(self, pointOne, pointTwo):
	#print('updating shooter coords')
	(p1x,p1y,p1w,p1h) = cv2.boundingRect(pointOne)
        p1x += p1w/2.0
        p1y += p1h/2.0
        (p2x,p2y,p2w,p2h) = cv2.boundingRect(pointTwo)
        p2x += p2w/2.0
        p2y += p2h/2.0
        self.shooter.putNumber('pointOneX', p1x)
        self.shooter.putNumber('pointOneY', p1y)
        self.shooter.putNumber('pointTwoX', p2x)
        self.shooter.putNumber('pointTwoY', p2y)
	#print('updated shooter coords')
    @classmethod
    def sender_exit(self):
	   self.sock.close()
	   #print('sender closed')

    @classmethod
    def is_match_over():
        return NetworkTables.getTable('cameraData').getBoolean("end", False)
class ImageRetriever:

    
    gearCam = cv2.VideoCapture(-1)
    shooterCam = cv2.VideoCapture(1)
    def __init__(self):
        for x in range(10):
            #print('Connecting to camera in ' + str(x) + '/10 seconds')
	    time.sleep(1)
        self.gearCam.set(cv2.CAP_PROP_FRAME_WIDTH, 360)
        self.gearCam.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)
        self.gearCam.set(cv2.CAP_PROP_FPS, 15)
        self.gearCam.set(cv2.CAP_PROP_EXPOSURE, 20)

        self.shooterCam.set(cv2.CAP_PROP_FRAME_WIDTH, 360)
        self.shooterCam.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)
        self.shooterCam.set(cv2.CAP_PROP_FPS, 15)
        self.shooterCam.set(cv2.CAP_PROP_EXPOSURE, 20)

        #self.vOut = cv2.VideoWriter('output.avi', -1, 15.0, (360, 240))

    @classmethod
    def get_latest_gear(self):
    	if Sender.is_match_over():
    		#vOut.release()
	lock.acquire()
        frame = self.gearCam.read()[1]
	time.sleep(0.05)
	#print('got latest gear: ' + str(len(frame)))
	lock.release()
	return frame
        
    @classmethod
    def get_latest_shooter(self):
	lock.acquire()
	frame = self.shooterCam.read()[1]
	time.sleep(0.05)
	#print('got latest shooter: ' + str(len(frame)))
	lock.release()
        return frame
    
    @classmethod
    def image_exit(self):
	self.shooterCam.release()
	self.gearCam.release()
	#print('image closed')


if __name__ == '__main__':
    global isOn
    isOn = True
    executive = Main()
    executive.start()

            

